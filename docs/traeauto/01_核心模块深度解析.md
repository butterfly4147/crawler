# 核心模块深度解析

## 模块概览

基于你的Go游戏服务器开发经验，这个分布式爬虫项目的核心模块设计与游戏服务器有很多相似之处。让我们从架构层面逐一分析各个核心模块。

## 1. Master模块 - 集群管理与任务调度

### 1.1 核心职责

Master模块类似于游戏服务器中的**主控节点**，负责：
- **Leader选举**: 通过etcd实现高可用的主节点选举
- **集群管理**: 监控Worker节点状态，维护集群拓扑
- **任务调度**: 基于负载均衡策略分配爬虫任务
- **资源管理**: 管理爬虫任务资源的生命周期

### 1.2 关键数据结构

```go
type Master struct {
    ID         string                        // Master节点唯一标识
    ready      int32                         // 就绪状态标志
    leaderID   string                        // 当前Leader节点ID
    workNodes  map[string]*NodeSpec          // Worker节点映射表
    resources  map[string]*ResourceSpec      // 任务资源映射表
    IDGen      *snowflake.Node              // 雪花算法ID生成器
    etcdCli    *clientv3.Client             // etcd客户端
    forwardCli proto.CrawlerMasterService   // 转发客户端
    rlock      sync.Mutex                   // 读写锁
}

// 节点规格定义
type NodeSpec struct {
    Node    *registry.Node  // 服务注册节点信息
    Payload int            // 当前负载量
}

// 资源规格定义
type ResourceSpec struct {
    ID           string  // 资源唯一标识
    Name         string  // 任务名称
    AssignedNode string  // 分配的节点
    CreationTime int64   // 创建时间
}
```

### 1.3 选举机制实现

```go
func (m *Master) Campaign() {
    // 基于etcd的concurrency.Election实现Leader选举
    session, err := concurrency.NewSession(m.etcdCli, concurrency.WithTTL(5))
    election := concurrency.NewElection(session, "/resources/election")
    
    // 参与选举
    go m.elect(election, ch)
    
    // 监听选举结果
    go func() {
        for resp := range election.Observe(context.Background()) {
            if string(resp.Kvs[0].Value) != m.ID {
                // 不是Leader，更新leaderID
                m.leaderID = string(resp.Kvs[0].Value)
            }
        }
    }()
}
```

**与游戏服务器的对比**:
- 类似于游戏服务器中的**主服务器选举**
- 使用etcd替代了传统的Raft或其他一致性算法
- 选举失败时自动成为Follower，转发请求到Leader

### 1.4 负载均衡策略

```go
func (m *Master) Assign(r *ResourceSpec) (*NodeSpec, error) {
    candidates := make([]*NodeSpec, 0, len(m.workNodes))
    for _, node := range m.workNodes {
        candidates = append(candidates, node)
    }
    
    // 按负载排序，选择负载最低的节点
    sort.Slice(candidates, func(i, j int) bool {
        return candidates[i].Payload < candidates[j].Payload
    })
    
    return candidates[0], nil
}
```

**负载均衡算法**: **最小负载优先**
- 类似于游戏服务器中的**玩家分配算法**
- 简单有效，避免热点节点
- 可扩展为加权轮询、一致性哈希等策略

## 2. Engine模块 - 爬虫引擎核心

### 2.1 核心职责

Engine模块是整个爬虫系统的**执行引擎**，类似于游戏服务器中的**游戏逻辑引擎**：
- **任务调度**: 管理爬虫任务的执行队列
- **并发控制**: 控制goroutine池，管理并发度
- **去重机制**: 避免重复抓取相同URL
- **失败重试**: 处理网络异常和解析失败
- **资源监听**: 监听etcd中的任务资源变化

### 2.2 关键数据结构

```go
type Crawler struct {
    id          string                              // 爬虫实例ID
    out         chan spider.ParseResult            // 结果输出通道
    Visited     map[string]bool                     // 已访问URL映射
    VisitedLock sync.Mutex                         // 访问锁
    failures    map[string]*spider.Request          // 失败请求映射
    failureLock sync.Mutex                         // 失败锁
    resources   map[string]*master.ResourceSpec     // 资源映射
    rlock       sync.Mutex                         // 资源锁
    etcdCli     *clientv3.Client                   // etcd客户端
}

type Schedule struct {
    requestCh   chan *spider.Request    // 请求通道
    workerCh    chan *spider.Request    // 工作通道
    priReqQueue []*spider.Request       // 优先级队列
    reqQueue    []*spider.Request       // 普通队列
    Logger      *zap.Logger            // 日志器
}
```

### 2.3 调度器设计

```go
func (s *Schedule) Schedule() {
    var req *spider.Request
    var ch chan *spider.Request
    
    // 优先级队列优先
    if len(s.priReqQueue) > 0 {
        req = s.priReqQueue[0]
        s.priReqQueue = s.priReqQueue[1:]
        ch = s.workerCh
    } else if len(s.reqQueue) > 0 {
        req = s.reqQueue[0]
        s.reqQueue = s.reqQueue[1:]
        ch = s.workerCh
    }
    
    select {
    case r := <-s.requestCh:
        // 新请求入队
        if r.Priority > 0 {
            s.priReqQueue = append(s.priReqQueue, r)
        } else {
            s.reqQueue = append(s.reqQueue, r)
        }
    case ch <- req:
        // 发送请求到工作协程
    }
}
```

**调度策略**:
- **优先级队列**: 高优先级任务优先执行
- **FIFO队列**: 普通任务按先进先出执行
- **通道通信**: 使用Go channel实现生产者-消费者模式

### 2.4 并发工作模型

```go
func (c *Crawler) CreateWork() {
    for {
        select {
        case req := <-c.scheduler.Pull():
            // 检查是否已访问
            if c.HasVisited(req) {
                continue
            }
            
            // 检查请求有效性
            if err := req.Check(); err != nil {
                continue
            }
            
            // 执行网页抓取
            body, err := req.Fetch()
            if err != nil {
                c.SetFailure(req)
                continue
            }
            
            // 执行内容解析
            rule := req.Task.Rule.Trunk[req.RuleName]
            result, err := rule.ParseFunc(&spider.Context{
                Body: body,
                Req:  req,
            })
            
            // 处理解析结果
            if len(result.Requesrts) > 0 {
                c.scheduler.Push(result.Requesrts...)
            }
            
            // 输出数据
            for _, item := range result.Items {
                c.out <- spider.ParseResult{Items: []interface{}{item}}
            }
            
            // 标记已访问
            c.StoreVisited(req)
        }
    }
}
```

**与游戏服务器的对比**:
- 类似于游戏服务器中的**任务处理循环**
- 使用goroutine池管理并发，类似于游戏中的**工作线程池**
- 通过channel实现异步通信，类似于游戏中的**消息队列**

### 2.5 去重与重试机制

```go
func (c *Crawler) HasVisited(r *spider.Request) bool {
    c.VisitedLock.Lock()
    defer c.VisitedLock.Unlock()
    unique := r.Unique()
    return c.Visited[unique]
}

func (c *Crawler) SetFailure(req *spider.Request) {
    c.failureLock.Lock()
    defer c.failureLock.Unlock()
    
    unique := req.Unique()
    if _, ok := c.failures[unique]; !ok {
        // 首次失败，重新入队
        c.failures[unique] = req
        c.scheduler.Push(req)
    }
    // 二次失败，丢弃请求
}
```

**去重策略**: 基于URL的MD5哈希去重
**重试策略**: 失败请求重试一次，避免网络抖动

## 3. Spider模块 - 任务定义与解析规则

### 3.1 核心职责

Spider模块定义了爬虫的**业务逻辑**，类似于游戏服务器中的**游戏规则定义**：
- **任务配置**: 定义爬虫任务的属性和行为
- **请求封装**: 封装HTTP请求的生命周期
- **解析规则**: 定义网页内容的解析逻辑
- **数据输出**: 定义数据的输出格式

### 3.2 任务定义结构

```go
type Task struct {
    Visited     map[string]bool  // 已访问URL
    VisitedLock sync.Mutex      // 访问锁
    Closed      bool            // 任务关闭标志
    Rule        RuleTree        // 解析规则树
    Options                     // 任务选项
}

type TaskConfig struct {
    Name     string        // 任务名称
    Cookie   string        // Cookie信息
    WaitTime int64         // 等待时间
    Reload   bool          // 是否可重复爬取
    MaxDepth int64         // 最大深度
    Fetcher  string        // 抓取器类型
    Limits   []LimitCofig  // 限流配置
}
```

### 3.3 解析规则树

```go
type RuleTree struct {
    Root  func() ([]*Request, error)  // 根节点(执行入口)
    Trunk map[string]*Rule            // 规则哈希表
}

type Rule struct {
    ItemFields []string                                    // 数据字段定义
    ParseFunc  func(*Context) (ParseResult, error)        // 解析函数
}
```

**规则树设计**:
- **Root**: 定义爬虫的入口URL和初始规则
- **Trunk**: 定义各个页面类型的解析规则
- **ParseFunc**: 具体的解析逻辑实现

### 3.4 请求生命周期

```go
type Request struct {
    Task     *Task    // 所属任务
    URL      string   // 请求URL
    Method   string   // HTTP方法
    Depth    int64    // 爬取深度
    Priority int64    // 优先级
    RuleName string   // 规则名称
    TmpData  *Temp    // 临时数据
}

func (r *Request) Fetch() ([]byte, error) {
    // 限流控制
    if err := r.Task.Limit.Wait(context.Background()); err != nil {
        return nil, err
    }
    
    // 执行HTTP请求
    return r.Task.Fetcher.Get(r)
}

func (r *Request) Check() error {
    // 检查深度限制
    if r.Depth > r.Task.MaxDepth {
        return errors.New("max depth limit reached")
    }
    
    // 检查重复爬取
    if !r.Task.Reload && r.Task.HasVisited(r) {
        return errors.New("already visited")
    }
    
    return nil
}
```

### 3.5 上下文与数据输出

```go
type Context struct {
    Body []byte    // 网页内容
    Req  *Request  // 当前请求
}

func (c *Context) Output(data interface{}) *DataCell {
    res := &DataCell{Task: c.Req.Task}
    res.Data = make(map[string]interface{})
    res.Data["Task"] = c.Req.Task.Name
    res.Data["Rule"] = c.Req.RuleName
    res.Data["Data"] = data
    res.Data["URL"] = c.Req.URL
    res.Data["Time"] = time.Now().Format("2006-01-02 15:04:05")
    return res
}

type ParseResult struct {
    Requesrts []*Request      // 新发现的请求
    Items     []interface{}  // 解析出的数据项
}
```

## 4. 模块间协作流程

### 4.1 任务执行流程

```
1. Master选举成功 → 加载任务配置
2. Worker启动 → 注册到etcd → Master感知新节点
3. Master分配任务 → 写入etcd资源路径
4. Worker监听资源变化 → 启动对应任务
5. Engine执行任务 → 调度器分发请求
6. Worker处理请求 → 抓取→解析→存储
7. 发现新链接 → 重新入队继续处理
```

### 4.2 分布式协作机制

```go
// Worker监听资源变化
func (c *Crawler) watchResource() {
    rch := c.etcdCli.Watch(context.Background(), master.RESOURCEPATH, clientv3.WithPrefix())
    for wresp := range rch {
        for _, ev := range wresp.Events {
            switch ev.Type {
            case clientv3.EventTypePut:
                // 新增任务
                c.runTasks(taskName)
            case clientv3.EventTypeDelete:
                // 删除任务
                c.deleteTasks(taskName)
            }
        }
    }
}
```

## 5. 与游戏服务器架构的深度对比

### 5.1 架构模式对比

| 组件 | 分布式爬虫 | 游戏服务器 | 相似度 |
|------|------------|------------|--------|
| Master | 任务调度中心 | 主服务器/大厅服务器 | 高 |
| Worker | 爬虫执行节点 | 游戏房间服务器 | 高 |
| etcd | 服务发现/配置中心 | 注册中心/配置服务 | 高 |
| Engine | 任务执行引擎 | 游戏逻辑引擎 | 中 |
| Spider | 业务规则定义 | 游戏规则定义 | 中 |

### 5.2 技术实现对比

| 技术点 | 分布式爬虫 | 游戏服务器 | 备注 |
|--------|------------|------------|------|
| 选举算法 | etcd选举 | Raft/Paxos | etcd内部使用Raft |
| 负载均衡 | 最小负载优先 | 玩家数量均衡 | 策略类似 |
| 并发模型 | goroutine池 | 线程池/协程池 | Go的优势 |
| 通信方式 | gRPC/HTTP | TCP/UDP/HTTP | 协议选择 |
| 状态管理 | 内存+etcd | 内存+数据库 | 持久化方式 |
| 容错机制 | 重试+转移 | 重连+切换 | 思路一致 |

### 5.3 学习建议

基于你的游戏服务器经验，建议重点关注：

1. **分布式协调**: etcd的使用方式，对比游戏服务器中的注册中心
2. **任务调度**: Engine的调度机制，对比游戏中的任务系统
3. **并发控制**: goroutine的使用模式，对比线程池管理
4. **状态同步**: 资源状态的同步机制，对比游戏状态同步
5. **容错设计**: 失败重试和故障转移，对比游戏服务器的容错

## 6. 扩展点分析

### 6.1 可扩展的接口

```go
// 抓取器接口 - 可扩展为浏览器、代理等
type Fetcher interface {
    Get(url *Request) ([]byte, error)
}

// 存储接口 - 可扩展为ES、ClickHouse等
type Storage interface {
    Save(data ...interface{}) error
}

// 调度器接口 - 可扩展为分布式队列
type Scheduler interface {
    Schedule()
    Push(...*Request)
    Pull() *Request
}
```

### 6.2 插件化设计

项目采用了良好的插件化设计，类似于游戏服务器中的模块化架构：
- **抓取器插件**: 支持HTTP、浏览器、代理等多种抓取方式
- **存储插件**: 支持MySQL、ES、文件等多种存储后端
- **解析插件**: 支持正则、XPath、JavaScript等多种解析方式

这种设计使得系统具有很好的可扩展性和可维护性，是分布式系统设计的最佳实践。